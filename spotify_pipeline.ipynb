{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2200abf4",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b43556",
   "metadata": {},
   "source": [
    "Spotify is one of the leading music streaming platforms in the world today. Founded in 2006, they initially used pirated tracks to demonstrate their proof of concept, but has since worked with record companies, big and small, and even with independent artists to rack up billions of streams across the world daily, thanks to their massive user base and proprietary algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d1591",
   "metadata": {},
   "source": [
    "<h2>Building the database</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec24234",
   "metadata": {},
   "source": [
    "Using Python as our primary tool, we will build a database of Daily Top 200 Tracks, with a selection of regions and a specifiable date range. This can be accomplished through web scraping using Selenium Webdriver to simulate logins and opening of the chart page for each date, reading the HTML elements of that page, inserting into a SQLite database, then moving onto the chart page for the next date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions in South East Asia with Spotify availability\n",
    "# the regions can be split across multiple scraping notebooks and run simulatenously to save time, but keep in mind request limits\n",
    "region_dict = {\n",
    "    \"id\" : \"Indonesia\",\n",
    "    \"my\" : \"Malaysia\",\n",
    "    \"ph\" : \"Philippines\",\n",
    "    \"sg\" : \"Singapore\",\n",
    "    \"th\" : \"Thailand\",\n",
    "    \"vn\" : \"Vietnam\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec67cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify date range\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2023-08-28'\n",
    "dates_list = pd.date_range(start=start_date, end=end_date).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the scraper uses the firefox engine Geckodriver and sqlite as the database, make sure to have it installed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.FirefoxOptions()\n",
    "\n",
    "driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()), options=options)\n",
    "print(\"Driver start\")\n",
    "\n",
    "driver.get(\"https://accounts.spotify.com/en/login?continue=https%3A%2F%2Fcharts.spotify.com/login\")\n",
    "\n",
    "username_field = driver.find_element(by=\"id\", value=\"login-username\")  # Replace with the actual username field ID\n",
    "password_field = driver.find_element(by=\"id\", value=\"login-password\")  # Replace with the actual password field ID\n",
    "login_button = driver.find_element(by=\"id\", value=\"login-button\")  # Replace with the actual login button ID\n",
    "\n",
    "# Enter login credentials\n",
    "username_field.send_keys(\"spotify-username\")\n",
    "password_field.send_keys(\"spotify-password\")\n",
    "\n",
    "# Click the login button\n",
    "login_button.click()\n",
    "\n",
    "# Now you can perform your automation tasks after logging in\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "try:\n",
    "    wait.until(EC.url_to_be('https://charts.spotify.com/charts/overview/global'))\n",
    "    print(\"login success, redirecting\")\n",
    "    print(\"***\")\n",
    "    \n",
    "    conn = sqlite3.connect('data/charts-sea.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # main scraping logic\n",
    "    for key in region_dict.keys():\n",
    "        \n",
    "        # todo: add mechanism to check if table already exists and has rows\n",
    "        # but not reaching the end date (most likely disconnected), and if yes continue on the last date scraped\n",
    "\n",
    "        cursor.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS {key} (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                title TEXT,\n",
    "                rank INTEGER,\n",
    "                date TEXT,\n",
    "                artist TEXT,\n",
    "                url TEXT,\n",
    "                region TEXT,\n",
    "                streams INTEGER\n",
    "            )\n",
    "        ''')\n",
    "\n",
    "        sub_chart = pd.DataFrame()\n",
    "\n",
    "        for date in dates_list:\n",
    "            date_string = date.strftime(\"%Y-%m-%d\")\n",
    "            driver.get(\"https://charts.spotify.com/charts/view/regional-\" + key + \"-daily/\" + date_string)\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"tr\")))\n",
    "                print(\"Page load https://charts.spotify.com/charts/view/regional-\" + key + \"-daily/\" + date_string + \" success!\")\n",
    "                print(\"Scraping \" + key + \" \" + date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "                titles = driver.find_elements(By.CLASS_NAME, \"kKOJRc\")\n",
    "                ranks = driver.find_elements(By.CLASS_NAME, \"hgLxdb\")\n",
    "                artists = driver.find_elements(By.CLASS_NAME, \"lfGOlT\")\n",
    "                artists = list(filter(lambda artists:\\\n",
    "                            len(artists.find_elements(By.CLASS_NAME, \"bVVLJU\")) > 0, artists))\n",
    "                urls = driver.find_elements(By.CLASS_NAME, \"gPJpnT\")\n",
    "                streams = driver.find_elements(By.CLASS_NAME, \"cltvtH\")\n",
    "\n",
    "                for title, rank, artist_list, url, streams_count in zip (titles, ranks, artists, urls, streams):\n",
    "                    title_string = title.text\n",
    "\n",
    "                    rank_string = rank.text\n",
    "\n",
    "                    artist_list_text_string = \"\"\n",
    "                    artist_list_text = []\n",
    "                    for artist in artist_list.find_elements(By.CLASS_NAME, \"bVVLJU\"):\n",
    "                        artist_list_text.append(artist.text)\n",
    "                    artist_list_text_string = ', '.join(map(str, artist_list_text))\n",
    "\n",
    "                    anchor = url.find_element(By.TAG_NAME, \"a\")\n",
    "                    anchor_string = anchor.get_attribute('href')\n",
    "\n",
    "                    streams_count_string = streams_count.find_element(By.XPATH, './preceding-sibling::*[1]').text\n",
    "\n",
    "                    cursor.execute(f'''INSERT INTO {key} (title, rank, date, artist, url, region, streams) VALUES (?, ?, ?, ?, ?, ?, ?)''',\\\n",
    "                                   (title_string, rank_string, date_string, artist_list_text_string, anchor_string, region_dict[key], streams_count_string))\n",
    "                    # commit row to db\n",
    "                    conn.commit()\n",
    "\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print(\"Page load https://charts.spotify.com/charts/view/regional-\" + key + \"-daily/\" + date_string + \" failed\")\n",
    "                print(\"Moving to next page..\")\n",
    "        \n",
    "        print(\"sleeping for 10 seconds\")\n",
    "        print(\"***\")\n",
    "        time.sleep(10)\n",
    "        \n",
    "    conn.close()\n",
    "    print(\"Last date reached, ending driver\")\n",
    "    driver.quit()\n",
    "        \n",
    "except:\n",
    "    print(\"login failed, ending driver\")\n",
    "    conn.close()\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7b9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
